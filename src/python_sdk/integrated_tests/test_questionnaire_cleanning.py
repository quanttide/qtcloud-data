"""
é—®å·æ•°æ®æ¸…æ´—é›†æˆæµ‹è¯•

æµ‹è¯•æµç¨‹ï¼ˆå‚è€ƒ docs/qa/questionnaire_cleanning.mdï¼‰ï¼š
1. å‡è®¾ç³»ç»Ÿå·²ç»å­˜åœ¨ spec çš„ base.md å’Œ questionnaire_cleanning.md
2. å§”æ‰˜äººæä¾› record çš„ questionnaire_raw.csv
3. ä»£ç†äººæä¾› blueprint çš„ questionnnare_cleanning
4. ç³»ç»Ÿç”Ÿæˆ schema çš„ questionnaire.json å’Œ processor çš„ questionnaire_cleanner.py
5. ç³»ç»Ÿè¿è¡Œ questionnaire_cleanning.py è·å¾— record çš„ questionnaire_cleanned.csv
6. ç³»ç»Ÿç”Ÿæˆ manifest çš„ questionnaire_cleanning.md
7. ç³»ç»Ÿæ‰“åŒ…ç”Ÿæˆ dataset çš„ questionnaire_cleanning.zip
"""

import pytest
import pandas as pd
import json
import zipfile
from pathlib import Path
import importlib.util
import tempfile
import shutil


class TestQuestionnaireCleaningPipeline:
    """æµ‹è¯•é—®å·æ•°æ®æ¸…æ´—çš„å®Œæ•´æµç¨‹"""

    @pytest.fixture
    def project_name(self):
        return "questionnaire_cleanning"

    @pytest.fixture
    def fixtures_root(self):
        return Path(__file__).parent / "fixtures"

    @pytest.fixture
    def project_path(self, fixtures_root, project_name):
        return fixtures_root / project_name

    # æ­¥éª¤1ï¼šéªŒè¯ spec æ–‡ä»¶å­˜åœ¨
    @pytest.fixture
    def spec_base_path(self, fixtures_root):
        """1. å‡è®¾ç³»ç»Ÿå·²ç»å­˜åœ¨ spec çš„ base.md"""
        path = fixtures_root / "spec" / "base.md"
        assert path.exists(), f"Spec base.md ä¸å­˜åœ¨: {path}"
        return path

    @pytest.fixture
    def spec_questionnaire_path(self, fixtures_root):
        """1. å‡è®¾ç³»ç»Ÿå·²ç»å­˜åœ¨ spec çš„ questionnaire_cleanning.md"""
        path = fixtures_root / "spec" / "questionnaire_cleanning.md"
        assert path.exists(), f"Spec questionnaire_cleanning.md ä¸å­˜åœ¨: {path}"
        return path

    # æ­¥éª¤2ï¼šéªŒè¯åŸå§‹æ•°æ®å­˜åœ¨
    @pytest.fixture
    def raw_data_path(self, project_path):
        """2. å§”æ‰˜äººæä¾› record çš„ questionnaire_raw.csv"""
        path = project_path / "record" / "questionnaire_raw.csv"
        assert path.exists(), f"åŸå§‹æ•°æ®ä¸å­˜åœ¨: {path}"
        return path

    @pytest.fixture
    def raw_data(self, raw_data_path):
        """è¯»å–åŸå§‹æ•°æ®"""
        return pd.read_csv(raw_data_path)

    # æ­¥éª¤3ï¼šéªŒè¯è“å›¾å­˜åœ¨
    @pytest.fixture
    def blueprint_path(self, project_path):
        """3. ä»£ç†äººæä¾› blueprint çš„ questionnnare_cleanning"""
        path = project_path / "blueprint" / "questionnare_cleanning.md"
        assert path.exists(), f"è“å›¾ä¸å­˜åœ¨: {path}"
        return path

    @pytest.fixture
    def blueprint_content(self, blueprint_path):
        """è¯»å–è“å›¾å†…å®¹"""
        return blueprint_path.read_text()

    # æ­¥éª¤4ï¼šéªŒè¯ç”Ÿæˆçš„ schema å’Œ processor
    @pytest.fixture
    def schema_path(self, project_path):
        """4. ç³»ç»Ÿç”Ÿæˆ schema çš„ questionnaire.json"""
        # æ³¨æ„ï¼šå½“å‰å®ç°ä¸­ schema ç›®å½•å¯èƒ½ä¸å­˜åœ¨ï¼Œè¿™ä¸ªæ˜¯é¢„æœŸè¡Œä¸º
        # å®é™…ç³»ç»Ÿåº”è¯¥åœ¨ processor ä¸­å®šä¹‰ schema
        return project_path / "schema" / "questionnaire.json"

    @pytest.fixture
    def processor_path(self, project_path):
        """4. ç³»ç»Ÿç”Ÿæˆ processor çš„ questionnaire_cleanner.py"""
        path = project_path / "processor" / "questionnaire_cleaner.py"
        assert path.exists(), f"å¤„ç†å™¨ä¸å­˜åœ¨: {path}"
        return path

    @pytest.fixture
    def processor_module(self, processor_path):
        """åŠ¨æ€åŠ è½½å¤„ç†å™¨æ¨¡å—"""
        spec = importlib.util.spec_from_file_location(
            "questionnaire_cleaner",
            processor_path
        )
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        return module

    @pytest.fixture
    def processor(self, processor_module):
        """åˆ›å»ºå¤„ç†å™¨å®ä¾‹"""
        return processor_module.QuestionnareCleaner()

    # æ­¥éª¤5ï¼šè¿è¡Œå¤„ç†å™¨ç”Ÿæˆæ¸…æ´—åæ•°æ®
    @pytest.fixture
    def cleaned_data_path(self, project_path):
        """5. ç³»ç»Ÿè¿è¡Œ questionnaire_cleanning.py è·å¾— record çš„ questionnaire_cleanned.csv"""
        path = project_path / "dataset" / "questionnaire_cleanned.csv"
        assert path.exists(), f"æ¸…æ´—åæ•°æ®ä¸å­˜åœ¨: {path}"
        return path

    @pytest.fixture
    def expected_cleaned_data(self, cleaned_data_path):
        """è¯»å–æœŸæœ›çš„æ¸…æ´—åæ•°æ®"""
        return pd.read_csv(cleaned_data_path)

    @pytest.fixture
    def actual_cleaned_data(self, raw_data, processor):
        """è¿è¡Œå¤„ç†å™¨è·å¾—å®é™…æ¸…æ´—åæ•°æ®"""
        return processor.process(raw_data)

    # æ­¥éª¤6ï¼šéªŒè¯äº¤ä»˜æ¸…å•
    @pytest.fixture
    def manifest_path(self, project_path):
        """6. ç³»ç»Ÿç”Ÿæˆ manifest çš„ questionnaire_cleanning.md"""
        path = project_path / "manifest" / "questionnaire_cleanning.md"
        assert path.exists(), f"äº¤ä»˜æ¸…å•ä¸å­˜åœ¨: {path}"
        return path

    @pytest.fixture
    def manifest_content(self, manifest_path):
        """è¯»å–äº¤ä»˜æ¸…å•å†…å®¹"""
        return manifest_path.read_text()

    # æ­¥éª¤7ï¼šéªŒè¯æ‰“åŒ…çš„ dataset
    @pytest.fixture
    def dataset_zip_path(self, project_path):
        """7. ç³»ç»Ÿæ‰“åŒ…ç”Ÿæˆ dataset çš„ questionnaire_cleanning.zip"""
        # æ³¨æ„ï¼šå½“å‰å®ç°ä¸­å¯èƒ½æ²¡æœ‰ç”Ÿæˆ zipï¼Œè¿™ä¸ªæ˜¯é¢„æœŸè¡Œä¸º
        # å®é™…ç³»ç»Ÿåº”è¯¥åœ¨æ‰€æœ‰éªŒè¯é€šè¿‡åæ‰“åŒ…
        return project_path / "dataset" / "questionnaire_cleanning.zip"

    # ========== æµ‹è¯•ç”¨ä¾‹ ==========

    def test_step1_spec_files_exist(self, spec_base_path, spec_questionnaire_path):
        """æ­¥éª¤1ï¼šéªŒè¯ spec æ–‡ä»¶å­˜åœ¨"""
        assert spec_base_path.exists()
        assert spec_questionnaire_path.exists()

        # éªŒè¯ spec å†…å®¹åŒ…å«å¿…éœ€ä¿¡æ¯
        spec_content = spec_questionnaire_path.read_text()
        assert "é—®å·æ•°æ®æ¸…æ´—" in spec_content or "æ•°æ®æ¸…æ´—" in spec_content

    def test_step2_raw_data_exists(self, raw_data_path):
        """æ­¥éª¤2ï¼šéªŒè¯åŸå§‹æ•°æ®å­˜åœ¨"""
        assert raw_data_path.exists()

        # éªŒè¯åŸå§‹æ•°æ®åŒ…å«å¿…è¦çš„åˆ—
        raw_data = pd.read_csv(raw_data_path)
        required_columns = ["æäº¤æ—¶é—´", "å¹´é¾„", "å·¥ä½œå¹´é™", "æ‰€å±éƒ¨é—¨"]
        for col in required_columns:
            assert col in raw_data.columns, f"åŸå§‹æ•°æ®ç¼ºå°‘åˆ—: {col}"

    def test_step3_blueprint_exists_and_valid(self, blueprint_path):
        """æ­¥éª¤3ï¼šéªŒè¯è“å›¾å­˜åœ¨ä¸”å†…å®¹æœ‰æ•ˆ"""
        assert blueprint_path.exists()

        content = blueprint_path.read_text()

        # éªŒè¯è“å›¾åŒ…å«å¿…éœ€ç« èŠ‚
        required_sections = ["## æ•°æ®æ¨¡å‹", "## æ•°æ®å¤„ç†æµç¨‹"]
        for section in required_sections:
            assert section in content, f"è“å›¾ç¼ºå°‘ç« èŠ‚: {section}"

        # éªŒè¯è“å›¾åŒ…å«å­—æ®µå®šä¹‰
        assert "å­—æ®µå" in content
        assert "ç±»å‹" in content
        assert "ç¼ºå¤±ç¼–ç " in content

    def test_step4_processor_exists_and_loadable(self, processor_path, processor_module):
        """æ­¥éª¤4ï¼šéªŒè¯å¤„ç†å™¨å­˜åœ¨ä¸”å¯åŠ è½½"""
        assert processor_path.exists()

        # éªŒè¯æ¨¡å—åŒ…å« QuestionnaireCleaner ç±»
        assert hasattr(processor_module, "QuestionnaireCleaner")

        # éªŒè¯å¤„ç†å™¨æœ‰å¿…éœ€çš„æ–¹æ³•
        cleaner = processor_module.QuestionnaireCleaner()
        assert hasattr(cleaner, "process")

    def test_step5_cleaning_produces_correct_output(
        self, actual_cleaned_data, expected_cleaned_data
    ):
        """æ­¥éª¤5ï¼šéªŒè¯æ¸…æ´—äº§ç”Ÿæ­£ç¡®çš„è¾“å‡º"""
        # éªŒè¯æ•°æ®å½¢çŠ¶
        assert actual_cleaned_data.shape == expected_cleaned_data.shape

        # éªŒè¯åˆ—åä¸€è‡´
        assert set(actual_cleaned_data.columns) == set(expected_cleaned_data.columns)

        # éªŒè¯æ•°æ®å†…å®¹ä¸€è‡´
        pd.testing.assert_frame_equal(
            actual_cleaned_data,
            expected_cleaned_data,
            check_dtype=False,
            check_like=True
        )

    def test_step5_cleaned_data_meets_blueprint(self, actual_cleaned_data, blueprint_content):
        """æ­¥éª¤5ï¼šéªŒè¯æ¸…æ´—åæ•°æ®ç¬¦åˆè“å›¾å®šä¹‰"""
        # éªŒè¯æ¸…æ´—åæ•°æ®åŒ…å«è“å›¾å®šä¹‰çš„å­—æ®µ
        blueprint_fields = []
        for line in blueprint_content.split('\n'):
            if line.startswith('| `'):
                field_name = line.split('`')[1]
                if field_name not in ['å­—æ®µå', 'åŸå§‹æ¥æº']:
                    blueprint_fields.append(field_name)

        # éªŒè¯æ‰€æœ‰è“å›¾å®šä¹‰çš„å­—æ®µéƒ½å­˜åœ¨äºè¾“å‡ºæ•°æ®ä¸­
        for field in blueprint_fields:
            assert field in actual_cleaned_data.columns, f"è¾“å‡ºæ•°æ®ç¼ºå°‘å­—æ®µ: {field}"

    def test_step6_manifest_exists_and_complete(self, manifest_path, project_path):
        """æ­¥éª¤6ï¼šéªŒè¯äº¤ä»˜æ¸…å•å­˜åœ¨ä¸”å®Œæ•´"""
        assert manifest_path.exists()

        content = manifest_path.read_text()

        # éªŒè¯æ¸…å•åŒ…å«å¿…éœ€ç« èŠ‚
        required_sections = [
            "## ğŸ“¦ äº¤ä»˜ç‰©æ¸…å•",
            "## ğŸ”„ æ•°æ®æµè½¬è·¯å¾„",
            "## âœ… è´¨é‡éªŒè¯"
        ]
        for section in required_sections:
            assert section in content, f"äº¤ä»˜æ¸…å•ç¼ºå°‘ç« èŠ‚: {section}"

        # éªŒè¯æ¸…å•æåŠæ‰€æœ‰äº¤ä»˜ç‰©
        assert "blueprint" in content.lower()
        assert "spec" in content.lower()
        assert "processor" in content.lower()
        assert "record" in content.lower()
        assert "dataset" in content.lower()
        assert "dataset" in content.lower()

    def test_step7_dataset_package_structure(self, project_path):
        """æ­¥éª¤7ï¼šéªŒè¯æ•°æ®é›†æ‰“åŒ…ç»“æ„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
        # æ³¨æ„ï¼šå½“å‰å¯èƒ½æ²¡æœ‰ç”Ÿæˆ zipï¼Œè¿™æ˜¯ä¸€ä¸ªå¯é€‰éªŒè¯
        zip_path = project_path / "dataset" / "questionnaire_cleanning.zip"

        if zip_path.exists():
            # éªŒè¯ zip æ–‡ä»¶åŒ…å«å¿…è¦çš„æ–‡ä»¶
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                file_list = zip_ref.namelist()

                # éªŒè¯åŒ…å«æ¸…æ´—åæ•°æ®
                assert any("questionnaire_cleanned.csv" in f for f in file_list)

    # ========== é¢å¤–çš„é›†æˆæµ‹è¯• ==========

    def test_end_to_end_pipeline(self, raw_data, processor, expected_cleaned_data):
        """ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä»åŸå§‹æ•°æ®åˆ°æ¸…æ´—åæ•°æ®"""
        # æ‰§è¡Œæ¸…æ´—
        actual_cleaned_data = processor.process(raw_data)

        # éªŒè¯è¾“å‡º
        pd.testing.assert_frame_equal(
            actual_cleaned_data,
            expected_cleaned_data,
            check_dtype=False,
            check_like=True
        )

    def test_data_quality_checks(self, actual_cleaned_data):
        """æ•°æ®è´¨é‡æ£€æŸ¥"""
        # æ£€æŸ¥å¿…å¡«å­—æ®µ
        assert actual_cleaned_data["submit_time"].notna().all(), "submit_time ä¸èƒ½ä¸ºç©º"

        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        age_values = actual_cleaned_data["age"]
        assert age_values.between(18, 70).all() or (age_values == -99).any(), \
            "å¹´é¾„åº”åœ¨18-70èŒƒå›´å†…æˆ–æ ‡è®°ä¸ºç¼ºå¤±"

        # æ£€æŸ¥éƒ¨é—¨ç¼–ç 
        dept_values = actual_cleaned_data["department"]
        valid_depts = [1, 2, 3, 4, 5, -99]
        assert dept_values.isin(valid_depts).all(), f"éƒ¨é—¨ç¼–ç æ— æ•ˆ: {dept_values.unique()}"

    def test_workflow_order(self):
        """éªŒè¯å·¥ä½œæµé¡ºåºç¬¦åˆæ–‡æ¡£å®šä¹‰"""
        # æ ¹æ® docs/qa/questionnaire_cleanning.md éªŒè¯æ­¥éª¤é¡ºåº
        expected_steps = [
            "spec base.md",
            "spec questionnaire_cleanning.md",
            "record questionnaire_raw.csv",
            "blueprint questionnare_cleanning",
            "processor questionnaire_cleaner.py",
            "dataset questionnaire_cleanned.csv",
            "manifest questionnare_cleanning.md",
        ]

        # è¿™ä¸ªæµ‹è¯•ä¸»è¦éªŒè¯æ–‡æ¡£æè¿°ä¸å®é™…å®ç°ä¸€è‡´
        assert len(expected_steps) == 7
